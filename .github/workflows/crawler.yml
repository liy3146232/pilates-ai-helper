name: Hot News Crawler
on:
  workflow_dispatch: # 允许手动运行
  schedule:
    # 每天UTC时间0点（北京时间8点）和12点（北京时间20点）各运行一次
    - cron: '0 0,12 * * *'

jobs:
  crawl:
    runs-on: ubuntu-latest
    steps:
      - name: 拉取代码
        uses: actions/checkout@v4

      - name: 设置Python环境
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: 安装依赖
        run: |
          pip install --upgrade pip
          pip install requests beautifulsoup4

      - name: 运行热点爬取与推送
        env:
          # 你只需要配置下面这一个，其他的都删除
          FEISHU_WEBHOOK_URL: ${{ secrets.FEISHU_WEBHOOK_URL }}
          # 如果你用钉钉，就用下面这行，并注释掉飞书那行
          # DINGTALK_WEBHOOK_URL: ${{ secrets.DINGTALK_WEBHOOK_URL }}
        run: |
          echo "开始运行..."
          # 这里简化执行一个Python脚本，我们马上会创建这个脚本
          python run_crawler.py
